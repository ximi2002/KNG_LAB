{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提升CPU利用率 1\n",
    "# 主内存->L3->L2->L1->寄存器\n",
    "# --L1访问延迟 0.5ns\n",
    "# --L2访问延迟 7ns\n",
    "# --主内存访问延迟 100ns\n",
    "# 提升时间和空间的内存本地性\n",
    "# 时间:重用数据使他们保持在缓存中\n",
    "# 空间:按序读取数据使得可以预读取\n",
    "# 矩阵按行存储，访问一行比访问一列快\n",
    "# CPU会读取64字节(缓存线)“聪明的读取\n",
    "# 连续地址存储，读取快\n",
    "# 提升CPU利用率 2\n",
    "# 并行计算(多线程)\n",
    "# Intel\n",
    "# 两个超线程公用寄存器(对数据计算密集型无用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.000997781753540039]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(1000000)\n",
    "b=torch.rand(1000000)\n",
    "c=torch.rand(1000000)\n",
    "timer=d2l.Timer()\n",
    "timer.start()\n",
    "c=a+b\n",
    "timer.stop()\n",
    "timer.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.000997781753540039, 7.772660255432129]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer.start()\n",
    "for i in range(1000000):\n",
    "    c[i]=a[i]+b[i]\n",
    "timer.stop()\n",
    "timer.cumsum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 调用有开销 差几万倍\n",
    "# 可以做并行\n",
    "# CPU 架构和优化方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\n",
    "# GPC\n",
    "# 上千个核，多线程\n",
    "# GPU 内存带宽大\n",
    "# 内存不大，高带宽的显存贵\n",
    "# GPU 都是简单的数值运算 不需要做多级显存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 问题是硬件的设计方式\n",
    "# 提升GPU利用率\n",
    "# -并行\n",
    "# --使用上千个线程\n",
    "# -内存本地性\n",
    "# --缓存更小，架构简单\n",
    "# -少用控制语句\n",
    "# --支持有限\n",
    "# --同步开销大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要频繁的在CPU和GPU之间传数据\n",
    "# 带宽限制，同步开销\n",
    "\n",
    "# CPU C++ 等高性能语言\n",
    "# --编译器成熟\n",
    "\n",
    "# GPU \n",
    "# -- Nvidia 用 CUDA\n",
    "# -- 编译器和驱动成熟\n",
    "# OpenCL\n",
    "# 质量取决于硬件厂商"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU:可以处理通用计算\n",
    "# 性能优化:读写效率和多线程\n",
    "# GPU:使用更多的小核和更好的内存带宽\n",
    "# 适合大规模并行计算任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更多的芯片\n",
    "\n",
    "# DSP:数字信号处理\n",
    "# 为数字信号处理算法设计:点积,卷积,FFT\n",
    "# 低功耗,高性能\n",
    "# VLIW:Very long instrucyion word\n",
    "# 一条指令上百次乘累加\n",
    "# 编程和调试特别困难\n",
    "# 编译器质量差\n",
    "\n",
    "# FPGA(可编程阵列)\n",
    "# 有大量可以编程的逻辑单元和可配置连接\n",
    "# 可以配置成计算复杂函数\n",
    "# VHDL,Verilog\n",
    "# 通常比通用硬件高效\n",
    "# 工具链差\n",
    "# \"编译\"需要数小时\n",
    "\n",
    "# AI ASIC (便宜)\n",
    "# 深度学习的热门领域\n",
    "# 自己的芯片\n",
    "# Google TPU\n",
    "# 核心 systolic array\n",
    "# 越通用越难 特定应用(硬件设计门槛低)\n",
    "\n",
    "# Systolic Array\n",
    "# 计算单元阵列\n",
    "# 特别适合做矩阵乘法\n",
    "# 设计制造简单\n",
    "# Matrix Multiolication with Systolic Array\n",
    "# 对于一般的矩阵进行切开和填充(矩阵分块)\n",
    "# 匹配SA大小\n",
    "# 批量输入减少延迟\n",
    "# 其他硬件单元处理别的NN操作子(Activate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 深度学习计算器\n",
    "# 只能跑这个任务\n",
    "# 专业性更强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=灵活性和易用性\n",
    "# y=性能和功耗\n",
    "# x+y=const\n",
    "# tensorflow 跑TPU\n",
    "# 芯片必须要有上面的生态\n",
    "# ASIC XPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2012 AlexNet\n",
    "# VGG\n",
    "# Inception\n",
    "# 2016 ResNet\n",
    "# AlexNet Conv_Full 完全不同\n",
    "# Conv 计算密集型(容易优化)\n",
    "# Full 不容易优化\n",
    "# ResNet 停滞\n",
    "# 卷积成熟了\n",
    "# 技术快速发展之后就稳定了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 硬件和软件\n",
    "# 鸡生蛋，蛋生鸡的问题\n",
    "# 硬件定义了软件设计架构和思路\n",
    "# Transformer\n",
    "# 特别适合跑 TPU\n",
    "# TPU内存很大 128G\n",
    "# 模型并行与数据并行\n",
    "# 硬件影响算法\n",
    "# 硬件必须有生态圈 开发生态和研究人员生态\n",
    "# 预测很难\n",
    "# 打包卖 NPU(套餐自带)\n",
    "# 关键在于开发人员使用什么\n",
    "# 深度学习框架不开源\n",
    "# 垄断才会商业化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多GPU并行\n",
    "# 单机多卡并行\n",
    "# 一台机器可以安装多个GPU(1-16)\n",
    "# 在训练和预测的时候，将小批量切分到多个GPU\n",
    "# 目的:加速\n",
    "# 切分方案\n",
    "# --数据并行(性能)\n",
    "# --模型并行(内存)\n",
    "# --通道并行(数据+模型并行)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 能用单卡计算时，通常使用数据并行拓展到多卡\n",
    "# 模型并行用在超大模型上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2l import torch as d2l \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('ogb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e823c50ccb644dc52d769ac47d58038dc0ab442baeffc4211a51b80e542be21a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
