{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积神经网络\n",
    "# MLP 参数量过大 不合适\n",
    "# 不如记忆所有图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两个原则\n",
    "# 平移不变性\n",
    "# 局部性\n",
    "# 图片处理 启发CNN设计\n",
    "# CNN 本质上是 MLP 的简化\n",
    "# 应用上述两个原则(平移不变性和局部性)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积层\n",
    "# 卷积实际上是交叉相关\n",
    "# 没有严格遵循卷积的定义\n",
    "# 1D,2D,3D 交叉相关(卷积)\n",
    "# 卷积层:将输入与核矩阵进行交叉相关,加上偏移\n",
    "# 可学习:核矩阵和偏移\n",
    "# 超参数:核矩阵的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像卷积\n",
    "import torch\n",
    "from torch import nn \n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import W\n",
    "\n",
    "\n",
    "def corr2d(X,K):\n",
    "    \"\"\"计算二维互相关\"\"\"\n",
    "    h,w=K.shape\n",
    "    Y=torch.zeros((X.shape[0]-h+1,X.shape[1]-w+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=(X[i:i+h,j:j+w]*K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.tensor(\n",
    "    [[0.,1.,2.],\n",
    "     [3.,4.,5.],\n",
    "     [6.,7.,8.]]\n",
    ")\n",
    "K=torch.tensor(\n",
    "    [[0.,1.],\n",
    "     [2.,3.]]\n",
    ")\n",
    "corr2d(X,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self,kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight=nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias=nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return corr2d(x,self.weight)+self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.ones((6,8))\n",
    "X[:,2:6]=0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=torch.tensor([[1.0,-1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=corr2d(X,K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X.t(),K)\n",
    "# 只能检测垂直边缘 不能检测水平边缘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "           [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "           [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "           [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "           [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "           [1., 1., 0., 0., 0., 0., 1., 1.]]]]),\n",
       " tensor([[[[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "           [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "           [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "           [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "           [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "           [ 0.,  1.,  0.,  0.,  0., -1.,  0.]]]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d=nn.Conv2d(1,1,kernel_size=(1,2),bias=False)\n",
    "\n",
    "X=X.reshape((1,1,6,8))\n",
    "Y=Y.reshape((1,1,6,7))\n",
    "\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 0.081\n",
      "epoch 4, loss 0.033\n",
      "epoch 6, loss 0.013\n",
      "epoch 8, loss 0.005\n",
      "epoch 10, loss 0.002\n",
      "epoch 12, loss 0.001\n",
      "epoch 14, loss 0.000\n",
      "epoch 16, loss 0.000\n",
      "epoch 18, loss 0.000\n",
      "epoch 20, loss 0.000\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    Y_hat=conv2d(X)\n",
    "    l=(Y_hat-Y)**2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    conv2d.weight.data[:]-=3e-2*conv2d.weight.grad\n",
    "    if (i+1)%2==0:\n",
    "        print(f\"epoch {i+1}, loss {l.sum():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9995, -1.0005]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data.reshape((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同样表达能力的深度卷积的参数比浅层更少 而且非线性性更好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积层的填充和步幅\n",
    "# 填充 Padding\n",
    "# 越卷越小\n",
    "# 在输出周围添加额外行列\n",
    "# 步幅 stride\n",
    "# 填充和步幅是卷积层的超参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_conv2d(conv2d,X):\n",
    "    X=X.reshape((1,1)+X.shape)\n",
    "    Y=conv2d(X)\n",
    "    return Y.reshape(Y.shape[2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding 指左右都填充了1行\n",
    "conv2d=nn.Conv2d(1,1,kernel_size=3,padding=1)\n",
    "X=torch.rand(size=(8,8))\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding 不对称\n",
    "conv2d=nn.Conv2d(1,1,kernel_size=(5,3),padding=(2,1))\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d=nn.Conv2d(1,1,kernel_size=3,padding=1,stride=2)\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d=nn.Conv2d(1,1,kernel_size=(3,5),padding=(0,1),stride=(3,4))\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一般使用对称的情况\n",
    "# 除非原始数据就shape偏差\n",
    "# 填充通常选2p=核-1\n",
    "# 保证size不变\n",
    "# 步幅=1最好 计算量过大 增加步幅=2\n",
    "# 均匀的插步幅=2的层\n",
    "# 奇数的核大小便于对称填充\n",
    "# 步幅和填充是架构的一部分\n",
    "# 除非数据特别奇怪，不然使用经典架构\n",
    "# 网络对训练的影响其实大家也不太知道\n",
    "# 自己设计 --数据集特殊 --硬件特殊\n",
    "# 机器学习 --压缩算法 --丢失信息\n",
    "# 计算机的像素信息-->人能理解的语义信息\n",
    "# 小的卷积核能减少计算量 但是效果相同\n",
    "# 简单的网络更容易被应用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多个输入和输出通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1*1 卷积层\n",
    "# 不识别空间信息,只是融合通道(加权和)\n",
    "# 每个输入空间的共享参数的全连接层\n",
    "# channel维的全连接层(共享参数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出通道数是卷积层的超参数\n",
    "# 输入通道 独立二维卷积核\n",
    "# 输出通道 独立三维卷积核\n",
    "# Filter 四维张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多输入和多输出通道\n",
    "def corr2d_multi_in(X,K):\n",
    "    return sum(d2l.corr2d(x,k) for x,k in zip(X,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 2],\n",
       "         [3, 4, 5],\n",
       "         [6, 7, 8]],\n",
       "\n",
       "        [[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.tensor([np.arange(9).reshape(3,3),np.arange(9).reshape(3,3)+1])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1],\n",
       "         [2, 3]],\n",
       "\n",
       "        [[1, 2],\n",
       "         [3, 4]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "K=torch.tensor([np.arange(4).reshape(2,2),np.arange(4).reshape(2,2)+1])\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in(X,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X,K):\n",
    "    return torch.stack([corr2d_multi_in(X,k) for k in K],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K=torch.stack((K,K+1,K+2),0)\n",
    "K.shape\n",
    "# 3个输出，2个输入，高2，宽2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1*1 卷积\n",
    "from inspect import CO_ASYNC_GENERATOR\n",
    "\n",
    "\n",
    "def corr2d_multi_in_out_1_1(X,K):\n",
    "    c_i,h,w=X.shape\n",
    "    c_o=K.shape[0]\n",
    "    X=X.reshape((c_i,h*w))\n",
    "    K=K.reshape((c_o,c_i))\n",
    "    # 转化成类似全连接\n",
    "    Y=torch.matmul(K,X)\n",
    "    return Y.reshape((c_o,h,w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.normal(0,1,(3,3,3))\n",
    "K=torch.normal(0,1,(2,3,1,1))\n",
    "\n",
    "Y1=corr2d_multi_in_out_1_1(X,K)\n",
    "Y2=corr2d_multi_in_out(X,K)\n",
    "\n",
    "float(torch.abs(Y1-Y2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch 调用\n",
    "# 见前面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 池化层\n",
    "# 积对位置敏感\n",
    "# 需要一定程度的平移不变性\n",
    "# 1像素移位导致0输出\n",
    "# 照明，物体位置，比例，外观\n",
    "# 二维最大池化\n",
    "# 允许输入发生小小的偏移\n",
    "# 相当于一种数据的模糊处理\n",
    "# 有填充和步幅\n",
    "# 没有可学习的参数\n",
    "# 输出通道数=输入通道数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(X,pool_size,mode=\"max\"):\n",
    "    p_h,p_w=pool_size\n",
    "    Y=torch.zeros((X.shape[0]-p_h+1,X.shape[1]-p_w+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode==\"max\":\n",
    "                Y[i,j]=X[i:i+p_h,j:j+p_w].max()\n",
    "            elif mode==\"avg\":\n",
    "                Y[i,j]=X[i:i+p_h,j:j+p_w].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.tensor(range(9),dtype=torch.float32).reshape(3,3)\n",
    "pool2d(X,(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X,(2,2),\"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.arange(16,dtype=torch.float32).reshape((1,1,4,4))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[10., 11.],\n",
       "          [14., 15.]]]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d=nn.MaxPool2d(3,stride=1)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d=nn.MaxPool2d(2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(1)\n",
    "pool2d(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 深度学习框架中默认步幅与池化窗口大小相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可设定任意大小\n",
    "pool2d=nn.MaxPool2d(3,padding=1,stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  3.],\n",
       "          [ 9., 11.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d=nn.MaxPool2d((2,3),padding=(1,1),stride=(2,3))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]],\n",
       "\n",
       "         [[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.cat((X,X+1),1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 少调用python的函数\n",
    "# 矩阵不用管，会自己释放内存\n",
    "# List.append 性能比 tensor.cat 好很多\n",
    "# 数据做增强 池化的效果不大 数据本身就有相当扰动\n",
    "# 数据保证不会过拟合 淡化池化的作用"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('ogb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e823c50ccb644dc52d769ac47d58038dc0ab442baeffc4211a51b80e542be21a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
