{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积神经网络\n",
    "# MLP 参数量过大 不合适\n",
    "# 不如记忆所有图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两个原则\n",
    "# 平移不变性\n",
    "# 局部性\n",
    "# 图片处理 启发CNN设计\n",
    "# CNN 本质上是 MLP 的简化\n",
    "# 应用上述两个原则(平移不变性和局部性)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积层\n",
    "# 卷积实际上是交叉相关\n",
    "# 没有严格遵循卷积的定义\n",
    "# 1D,2D,3D 交叉相关(卷积)\n",
    "# 卷积层:将输入与核矩阵进行交叉相关,加上偏移\n",
    "# 可学习:核矩阵和偏移\n",
    "# 超参数:核矩阵的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像卷积\n",
    "import torch\n",
    "from torch import nn \n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import W\n",
    "\n",
    "\n",
    "def corr2d(X,K):\n",
    "    \"\"\"计算二维互相关\"\"\"\n",
    "    h,w=K.shape\n",
    "    Y=torch.zeros((X.shape[0]-h+1,X.shape[1]-w+1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j]=(X[i:i+h,j:j+w]*K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19., 25.],\n",
       "        [37., 43.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.tensor(\n",
    "    [[0.,1.,2.],\n",
    "     [3.,4.,5.],\n",
    "     [6.,7.,8.]]\n",
    ")\n",
    "K=torch.tensor(\n",
    "    [[0.,1.],\n",
    "     [2.,3.]]\n",
    ")\n",
    "corr2d(X,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self,kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight=nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias=nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return corr2d(x,self.weight)+self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=torch.ones((6,8))\n",
    "X[:,2:6]=0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "K=torch.tensor([[1.0,-1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=corr2d(X,K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X.t(),K)\n",
    "# 只能检测垂直边缘 不能检测水平边缘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "           [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "           [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "           [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "           [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "           [1., 1., 0., 0., 0., 0., 1., 1.]]]]),\n",
       " tensor([[[[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "           [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "           [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "           [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "           [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "           [ 0.,  1.,  0.,  0.,  0., -1.,  0.]]]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d=nn.Conv2d(1,1,kernel_size=(1,2),bias=False)\n",
    "\n",
    "X=X.reshape((1,1,6,8))\n",
    "Y=Y.reshape((1,1,6,7))\n",
    "\n",
    "X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 0.081\n",
      "epoch 4, loss 0.033\n",
      "epoch 6, loss 0.013\n",
      "epoch 8, loss 0.005\n",
      "epoch 10, loss 0.002\n",
      "epoch 12, loss 0.001\n",
      "epoch 14, loss 0.000\n",
      "epoch 16, loss 0.000\n",
      "epoch 18, loss 0.000\n",
      "epoch 20, loss 0.000\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    Y_hat=conv2d(X)\n",
    "    l=(Y_hat-Y)**2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    conv2d.weight.data[:]-=3e-2*conv2d.weight.grad\n",
    "    if (i+1)%2==0:\n",
    "        print(f\"epoch {i+1}, loss {l.sum():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9995, -1.0005]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data.reshape((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同样表达能力的深度卷积的参数比浅层更少 而且非线性性更好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积层的填充和步幅\n",
    "# 填充 Padding\n",
    "# 越卷越小\n",
    "# 在输出周围添加额外行列\n",
    "# 步幅 stride\n",
    "# 填充和步幅是卷积层的超参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_conv2d(conv2d,X):\n",
    "    X=X.reshape((1,1)+X.shape)\n",
    "    Y=conv2d(X)\n",
    "    return Y.reshape(Y.shape[2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding 指左右都填充了1行\n",
    "conv2d=nn.Conv2d(1,1,kernel_size=3,padding=1)\n",
    "X=torch.rand(size=(8,8))\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding 不对称\n",
    "conv2d=nn.Conv2d(1,1,kernel_size=(5,3),padding=(2,1))\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d=nn.Conv2d(1,1,kernel_size=3,padding=1,stride=2)\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d=nn.Conv2d(1,1,kernel_size=(3,5),padding=(0,1),stride=(3,4))\n",
    "comp_conv2d(conv2d,X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一般使用对称的情况\n",
    "# 除非原始数据就shape偏差\n",
    "# 填充通常选2p=核-1\n",
    "# 保证size不变\n",
    "# 步幅=1最好 计算量过大 增加步幅=2\n",
    "# 均匀的插步幅=2的层\n",
    "# 奇数的核大小便于对称填充\n",
    "# 步幅和填充是架构的一部分\n",
    "# 除非数据特别奇怪，不然使用经典架构\n",
    "# 网络对训练的影响其实大家也不太知道\n",
    "# 自己设计 --数据集特殊 --硬件特殊\n",
    "# 机器学习 --压缩算法 --丢失信息\n",
    "# 计算机的像素信息-->人能理解的语义信息\n",
    "# 小的卷积核能减少计算量 但是效果相同\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 ('ogb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e823c50ccb644dc52d769ac47d58038dc0ab442baeffc4211a51b80e542be21a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
