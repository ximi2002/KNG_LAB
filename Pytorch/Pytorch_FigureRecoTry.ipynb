{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2245de5",
   "metadata": {},
   "source": [
    "### 使用 pytorch 完成手写数字的识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9becdfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose,ToTensor,Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5d54e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据集\n",
    "def get_dataloader(train=True,batch_size=BATCH_SIZE):\n",
    "    transform_fn=Compose([\n",
    "        ToTensor(),\n",
    "        Normalize(mean=(0.1307,),std=(0.3081,))\n",
    "    ])\n",
    "    dataset=MNIST(root=\"/home/suzhang/git/Pytorch/HandWritingRecoData\",train=train,transform=transform_fn)\n",
    "    data_loader=DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd751712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# 构建模型\n",
    "\n",
    "# 激活函数\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import nn\n",
    "b=torch.tensor([-2,-1,0,1,2])\n",
    "F.relu(b)\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "026cd828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据的形状 now [BATCH_SIZE,1,28,28]\n",
    "#            input1 [BATCH_SIZE,28*28]\n",
    "#            output1 [BATCH_SIZE,28]\n",
    "#            input1 [BATCH_SIZE,28]\n",
    "#            output2 [BATCH_SIZE,10]\n",
    "# 形状的修改\n",
    "\n",
    "class MnistNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MnistNet,self).__init__()\n",
    "        self.fc1=nn.Linear(28*28*1,28)\n",
    "        self.fc2=nn.Linear(28,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x:[batch_size,1,28,28]\n",
    "        # 最后一部分可能不满\n",
    "        # x.size(0)也可\n",
    "        # 修改形状\n",
    "        x=x.view([-1,28*28*1])\n",
    "\n",
    "        # 全连接操作\n",
    "        x=self.fc1(x)\n",
    "        # 激活函数处理（形状无变化）\n",
    "        x=F.relu(x)\n",
    "        # 全输出层\n",
    "        x=self.fc2(x)\n",
    "\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f6721e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数(交叉熵)\n",
    "# 训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ea66f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "mnist_net=MnistNet().to(device)\n",
    "optimizer=optim.Adam(mnist_net.parameters(),lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b3a54570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def train(epoch):\n",
    "    data_loader=get_dataloader()\n",
    "    for idx,(Input,target) in enumerate(data_loader):\n",
    "        Input=Input.to(device)\n",
    "        target=target.to(device)\n",
    "        output=mnist_net(Input)\n",
    "        logput=F.log_softmax(output,dim=-1)\n",
    "        loss=F.nll_loss(logput,target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if idx%10==0:\n",
    "            print(epoch,idx,loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c4de98d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.02532069757580757\n",
      "0 10 0.06606400012969971\n",
      "0 20 0.07008245587348938\n",
      "0 30 0.0978085920214653\n",
      "0 40 0.045961894094944\n",
      "0 50 0.05757028982043266\n",
      "0 60 0.08797620236873627\n",
      "0 70 0.024240365251898766\n",
      "0 80 0.04234069213271141\n",
      "0 90 0.05490914359688759\n",
      "0 100 0.10631413757801056\n",
      "0 110 0.037515103816986084\n",
      "0 120 0.04025069996714592\n",
      "0 130 0.05632774159312248\n",
      "0 140 0.07919642329216003\n",
      "0 150 0.10952959954738617\n",
      "0 160 0.09345036000013351\n",
      "0 170 0.09402614831924438\n",
      "0 180 0.08855807781219482\n",
      "0 190 0.06196647137403488\n",
      "0 200 0.07229217141866684\n",
      "0 210 0.09847632050514221\n",
      "0 220 0.06074308604001999\n",
      "0 230 0.14775444567203522\n",
      "0 240 0.03247573599219322\n",
      "0 250 0.08614680916070938\n",
      "0 260 0.06386097520589828\n",
      "0 270 0.1026415154337883\n",
      "0 280 0.05724901705980301\n",
      "0 290 0.026624079793691635\n",
      "0 300 0.09692341089248657\n",
      "0 310 0.05262065306305885\n",
      "0 320 0.047548964619636536\n",
      "0 330 0.027170751243829727\n",
      "0 340 0.04733964800834656\n",
      "0 350 0.019532909616827965\n",
      "0 360 0.08195815980434418\n",
      "0 370 0.13630469143390656\n",
      "0 380 0.036794718354940414\n",
      "0 390 0.07658707350492477\n",
      "0 400 0.020928259938955307\n",
      "0 410 0.10421241819858551\n",
      "0 420 0.059484098106622696\n",
      "0 430 0.0988226905465126\n",
      "0 440 0.050949759781360626\n",
      "0 450 0.03439129516482353\n",
      "0 460 0.05415378883481026\n",
      "1 0 0.03020184300839901\n",
      "1 10 0.04787517711520195\n",
      "1 20 0.13196660578250885\n",
      "1 30 0.055841632187366486\n",
      "1 40 0.044281091541051865\n",
      "1 50 0.05185724422335625\n",
      "1 60 0.11476489901542664\n",
      "1 70 0.11060081422328949\n",
      "1 80 0.04620013013482094\n",
      "1 90 0.04867667704820633\n",
      "1 100 0.05485597252845764\n",
      "1 110 0.04234125465154648\n",
      "1 120 0.03350243717432022\n",
      "1 130 0.043286435306072235\n",
      "1 140 0.06933696568012238\n",
      "1 150 0.11515024304389954\n",
      "1 160 0.042652059346437454\n",
      "1 170 0.05576050281524658\n",
      "1 180 0.11059634387493134\n",
      "1 190 0.09252075850963593\n",
      "1 200 0.042345982044935226\n",
      "1 210 0.045230913907289505\n",
      "1 220 0.08265528082847595\n",
      "1 230 0.039111409336328506\n",
      "1 240 0.11265664547681808\n",
      "1 250 0.06438486278057098\n",
      "1 260 0.11821600794792175\n",
      "1 270 0.11547750979661942\n",
      "1 280 0.06547233462333679\n",
      "1 290 0.08601225167512894\n",
      "1 300 0.08055870234966278\n",
      "1 310 0.07757139205932617\n",
      "1 320 0.07201864570379257\n",
      "1 330 0.1374630481004715\n",
      "1 340 0.1651625782251358\n",
      "1 350 0.03780942037701607\n",
      "1 360 0.10428782552480698\n",
      "1 370 0.08006569743156433\n",
      "1 380 0.06984681636095047\n",
      "1 390 0.02696666680276394\n",
      "1 400 0.08891380578279495\n",
      "1 410 0.029658207669854164\n",
      "1 420 0.16571837663650513\n",
      "1 430 0.021596873179078102\n",
      "1 440 0.04787123575806618\n",
      "1 450 0.07301618158817291\n",
      "1 460 0.04771842807531357\n",
      "2 0 0.04110502079129219\n",
      "2 10 0.08497852832078934\n",
      "2 20 0.11456295847892761\n",
      "2 30 0.10771669447422028\n",
      "2 40 0.060544706881046295\n",
      "2 50 0.05200498551130295\n",
      "2 60 0.07226884365081787\n",
      "2 70 0.03220254182815552\n",
      "2 80 0.07240438461303711\n",
      "2 90 0.055572837591171265\n",
      "2 100 0.07191011309623718\n",
      "2 110 0.02339145913720131\n",
      "2 120 0.030083993449807167\n",
      "2 130 0.1616293340921402\n",
      "2 140 0.037051036953926086\n",
      "2 150 0.0270291268825531\n",
      "2 160 0.07121529430150986\n",
      "2 170 0.07028345763683319\n",
      "2 180 0.11646568775177002\n",
      "2 190 0.032558731734752655\n",
      "2 200 0.050345249474048615\n",
      "2 210 0.08230017870664597\n",
      "2 220 0.0573686920106411\n",
      "2 230 0.02209298312664032\n",
      "2 240 0.0821971669793129\n",
      "2 250 0.09335407614707947\n",
      "2 260 0.07098182290792465\n",
      "2 270 0.04177561029791832\n",
      "2 280 0.057372912764549255\n",
      "2 290 0.051970887929201126\n",
      "2 300 0.06413761526346207\n",
      "2 310 0.04224424436688423\n",
      "2 320 0.1166573315858841\n",
      "2 330 0.02647790126502514\n",
      "2 340 0.1359616070985794\n",
      "2 350 0.029182301834225655\n",
      "2 360 0.06624940782785416\n",
      "2 370 0.08495845645666122\n",
      "2 380 0.03447470813989639\n",
      "2 390 0.08392676711082458\n",
      "2 400 0.12182101607322693\n",
      "2 410 0.022980792447924614\n",
      "2 420 0.06059566140174866\n",
      "2 430 0.08097054809331894\n",
      "2 440 0.15508335828781128\n",
      "2 450 0.06968078762292862\n",
      "2 460 0.03817044943571091\n",
      "3 0 0.07234343141317368\n",
      "3 10 0.02923433668911457\n",
      "3 20 0.08550194650888443\n",
      "3 30 0.04213828220963478\n",
      "3 40 0.03453285992145538\n",
      "3 50 0.05067281052470207\n",
      "3 60 0.07891855388879776\n",
      "3 70 0.06748312711715698\n",
      "3 80 0.12986181676387787\n",
      "3 90 0.07338687032461166\n",
      "3 100 0.03260692581534386\n",
      "3 110 0.023823600262403488\n",
      "3 120 0.06129247322678566\n",
      "3 130 0.044351547956466675\n",
      "3 140 0.03674055263400078\n",
      "3 150 0.0938970297574997\n",
      "3 160 0.04675043374300003\n",
      "3 170 0.047181595116853714\n",
      "3 180 0.043995585292577744\n",
      "3 190 0.11281221359968185\n",
      "3 200 0.06113822013139725\n",
      "3 210 0.10500305891036987\n",
      "3 220 0.024264728650450706\n",
      "3 230 0.05333282798528671\n",
      "3 240 0.0527295358479023\n",
      "3 250 0.0649593397974968\n",
      "3 260 0.03144354000687599\n",
      "3 270 0.02871423214673996\n",
      "3 280 0.04499197378754616\n",
      "3 290 0.07193530350923538\n",
      "3 300 0.014803835190832615\n",
      "3 310 0.039458271116018295\n",
      "3 320 0.029061993584036827\n",
      "3 330 0.034792132675647736\n",
      "3 340 0.1134834885597229\n",
      "3 350 0.1555616855621338\n",
      "3 360 0.1037382110953331\n",
      "3 370 0.061819273978471756\n",
      "3 380 0.015525469556450844\n",
      "3 390 0.029905110597610474\n",
      "3 400 0.02130555920302868\n",
      "3 410 0.06753009557723999\n",
      "3 420 0.02612578310072422\n",
      "3 430 0.11429908871650696\n",
      "3 440 0.030957721173763275\n",
      "3 450 0.08478479832410812\n",
      "3 460 0.055428553372621536\n",
      "4 0 0.021004509180784225\n",
      "4 10 0.03673999756574631\n",
      "4 20 0.0615948885679245\n",
      "4 30 0.11357130855321884\n",
      "4 40 0.03626827523112297\n",
      "4 50 0.03466343879699707\n",
      "4 60 0.052940621972084045\n",
      "4 70 0.038272418081760406\n",
      "4 80 0.025688545778393745\n",
      "4 90 0.039057955145835876\n",
      "4 100 0.0834018737077713\n",
      "4 110 0.06252384930849075\n",
      "4 120 0.04543737322092056\n",
      "4 130 0.03777286037802696\n",
      "4 140 0.017506862059235573\n",
      "4 150 0.020729750394821167\n",
      "4 160 0.050043486058712006\n",
      "4 170 0.11304263770580292\n",
      "4 180 0.12771199643611908\n",
      "4 190 0.08510857820510864\n",
      "4 200 0.09786005318164825\n",
      "4 210 0.08093831688165665\n",
      "4 220 0.11680417507886887\n",
      "4 230 0.029846597462892532\n",
      "4 240 0.031500693410634995\n",
      "4 250 0.1870109885931015\n",
      "4 260 0.05992303416132927\n",
      "4 270 0.053197648376226425\n",
      "4 280 0.05539823696017265\n",
      "4 290 0.0879582092165947\n",
      "4 300 0.0680978074669838\n",
      "4 310 0.03051987662911415\n",
      "4 320 0.030771788209676743\n",
      "4 330 0.16138823330402374\n",
      "4 340 0.05809172987937927\n",
      "4 350 0.038786545395851135\n",
      "4 360 0.1634058952331543\n",
      "4 370 0.06329213827848434\n",
      "4 380 0.02969791740179062\n",
      "4 390 0.02598850056529045\n",
      "4 400 0.04515741765499115\n",
      "4 410 0.008443303406238556\n",
      "4 420 0.028295332565903664\n",
      "4 430 0.10060228407382965\n",
      "4 440 0.029551273211836815\n",
      "4 450 0.06927171349525452\n",
      "4 460 0.09137950837612152\n",
      "5 0 0.04679189622402191\n",
      "5 10 0.09728311747312546\n",
      "5 20 0.047517068684101105\n",
      "5 30 0.04884999990463257\n",
      "5 40 0.02168731763958931\n",
      "5 50 0.05267202854156494\n",
      "5 60 0.0963503047823906\n",
      "5 70 0.056760165840387344\n",
      "5 80 0.028124947100877762\n",
      "5 90 0.09049222618341446\n",
      "5 100 0.05111074820160866\n",
      "5 110 0.0254893209785223\n",
      "5 120 0.028321098536252975\n",
      "5 130 0.04764101654291153\n",
      "5 140 0.02176256850361824\n",
      "5 150 0.07712527364492416\n",
      "5 160 0.08316556364297867\n",
      "5 170 0.056288059800863266\n",
      "5 180 0.010988440364599228\n",
      "5 190 0.02141740918159485\n",
      "5 200 0.026959922164678574\n",
      "5 210 0.036669936031103134\n",
      "5 220 0.03600696474313736\n",
      "5 230 0.10207834839820862\n",
      "5 240 0.09556436538696289\n",
      "5 250 0.035982586443424225\n",
      "5 260 0.07987350225448608\n",
      "5 270 0.0838465616106987\n",
      "5 280 0.02580050565302372\n",
      "5 290 0.060991834849119186\n",
      "5 300 0.05412643402814865\n",
      "5 310 0.0345650315284729\n",
      "5 320 0.0906195268034935\n",
      "5 330 0.045561712235212326\n",
      "5 340 0.030265815556049347\n",
      "5 350 0.0633406862616539\n",
      "5 360 0.05546678602695465\n",
      "5 370 0.04109737649559975\n",
      "5 380 0.055499106645584106\n",
      "5 390 0.029532095417380333\n",
      "5 400 0.019835490733385086\n",
      "5 410 0.09987059980630875\n",
      "5 420 0.06767904758453369\n",
      "5 430 0.01630784384906292\n",
      "5 440 0.028436329215765\n",
      "5 450 0.06889677792787552\n",
      "5 460 0.05882079526782036\n",
      "6 0 0.02705758437514305\n",
      "6 10 0.05995940417051315\n",
      "6 20 0.04934421926736832\n",
      "6 30 0.04115581139922142\n",
      "6 40 0.034128494560718536\n",
      "6 50 0.10502634197473526\n",
      "6 60 0.05460264906287193\n",
      "6 70 0.03456111624836922\n",
      "6 80 0.03863447159528732\n",
      "6 90 0.02393164299428463\n",
      "6 100 0.02230265364050865\n",
      "6 110 0.038306936621665955\n",
      "6 120 0.18374677002429962\n",
      "6 130 0.046392280608415604\n",
      "6 140 0.10194267332553864\n",
      "6 150 0.019590800628066063\n",
      "6 160 0.029781457036733627\n",
      "6 170 0.07285305112600327\n",
      "6 180 0.029948731884360313\n",
      "6 190 0.04960983991622925\n",
      "6 200 0.08630402386188507\n",
      "6 210 0.13905055820941925\n",
      "6 220 0.08676526695489883\n",
      "6 230 0.022676069289445877\n",
      "6 240 0.03708292171359062\n",
      "6 250 0.033879924565553665\n",
      "6 260 0.04938910901546478\n",
      "6 270 0.05598647892475128\n",
      "6 280 0.07063524425029755\n",
      "6 290 0.033183034509420395\n",
      "6 300 0.056512802839279175\n",
      "6 310 0.055252477526664734\n",
      "6 320 0.06704896688461304\n",
      "6 330 0.03550347685813904\n",
      "6 340 0.08760695159435272\n",
      "6 350 0.016672426834702492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 360 0.10319285839796066\n",
      "6 370 0.06268235296010971\n",
      "6 380 0.04660429432988167\n",
      "6 390 0.024313632398843765\n",
      "6 400 0.055693864822387695\n",
      "6 410 0.03994910046458244\n",
      "6 420 0.0854753702878952\n",
      "6 430 0.03377274423837662\n",
      "6 440 0.029053762555122375\n",
      "6 450 0.02943437360227108\n",
      "6 460 0.04887093976140022\n",
      "7 0 0.029601991176605225\n",
      "7 10 0.04493428021669388\n",
      "7 20 0.02121499739587307\n",
      "7 30 0.02658945880830288\n",
      "7 40 0.026546228677034378\n",
      "7 50 0.04750281199812889\n",
      "7 60 0.025814982131123543\n",
      "7 70 0.015782466158270836\n",
      "7 80 0.02846686728298664\n",
      "7 90 0.14063477516174316\n",
      "7 100 0.04230072721838951\n",
      "7 110 0.017017124220728874\n",
      "7 120 0.06688115000724792\n",
      "7 130 0.08717996627092361\n",
      "7 140 0.018534624949097633\n",
      "7 150 0.02575472928583622\n",
      "7 160 0.02617744915187359\n",
      "7 170 0.059476517140865326\n",
      "7 180 0.0324057899415493\n",
      "7 190 0.10888189822435379\n",
      "7 200 0.11493223905563354\n",
      "7 210 0.025856809690594673\n",
      "7 220 0.060347650200128555\n",
      "7 230 0.09279391169548035\n",
      "7 240 0.11004915088415146\n",
      "7 250 0.016559522598981857\n",
      "7 260 0.0591721348464489\n",
      "7 270 0.03575186803936958\n",
      "7 280 0.03090755268931389\n",
      "7 290 0.03358136862516403\n",
      "7 300 0.027422836050391197\n",
      "7 310 0.04546878859400749\n",
      "7 320 0.03168116509914398\n",
      "7 330 0.041475798934698105\n",
      "7 340 0.04299989342689514\n",
      "7 350 0.04521019756793976\n",
      "7 360 0.05462689325213432\n",
      "7 370 0.10194563120603561\n",
      "7 380 0.02703707665205002\n",
      "7 390 0.019630933180451393\n",
      "7 400 0.11615686863660812\n",
      "7 410 0.034047577530145645\n",
      "7 420 0.07545888423919678\n",
      "7 430 0.04497012868523598\n",
      "7 440 0.07677888125181198\n",
      "7 450 0.027864569798111916\n",
      "7 460 0.053551025688648224\n",
      "8 0 0.06549578905105591\n",
      "8 10 0.03551110252737999\n",
      "8 20 0.009312880225479603\n",
      "8 30 0.1076907217502594\n",
      "8 40 0.00695565901696682\n",
      "8 50 0.08847281336784363\n",
      "8 60 0.04175831377506256\n",
      "8 70 0.04500395059585571\n",
      "8 80 0.045761726796627045\n",
      "8 90 0.04423487186431885\n",
      "8 100 0.0303311999887228\n",
      "8 110 0.06164533644914627\n",
      "8 120 0.05263948813080788\n",
      "8 130 0.0120762400329113\n",
      "8 140 0.10279180854558945\n",
      "8 150 0.07586725056171417\n",
      "8 160 0.04299516603350639\n",
      "8 170 0.07866695523262024\n",
      "8 180 0.053574636578559875\n",
      "8 190 0.08945741504430771\n",
      "8 200 0.03443014621734619\n",
      "8 210 0.025281650945544243\n",
      "8 220 0.08840963244438171\n",
      "8 230 0.05268898606300354\n",
      "8 240 0.0553484745323658\n",
      "8 250 0.031789034605026245\n",
      "8 260 0.06946579366922379\n",
      "8 270 0.03243229165673256\n",
      "8 280 0.02007562294602394\n",
      "8 290 0.02358534373342991\n",
      "8 300 0.01568017713725567\n",
      "8 310 0.028752699494361877\n",
      "8 320 0.046114273369312286\n",
      "8 330 0.015806524083018303\n",
      "8 340 0.06756216287612915\n",
      "8 350 0.04906968027353287\n",
      "8 360 0.08957581967115402\n",
      "8 370 0.02547265589237213\n",
      "8 380 0.015156715176999569\n",
      "8 390 0.14367936551570892\n",
      "8 400 0.0601518452167511\n",
      "8 410 0.05175001919269562\n",
      "8 420 0.0172241423279047\n",
      "8 430 0.10975392907857895\n",
      "8 440 0.06985302269458771\n",
      "8 450 0.0312630832195282\n",
      "8 460 0.03326071426272392\n",
      "9 0 0.046635378152132034\n",
      "9 10 0.0418398343026638\n",
      "9 20 0.017492003738880157\n",
      "9 30 0.02089654840528965\n",
      "9 40 0.0333455428481102\n",
      "9 50 0.07037586718797684\n",
      "9 60 0.06483569741249084\n",
      "9 70 0.021043019369244576\n",
      "9 80 0.04629739746451378\n",
      "9 90 0.04734232276678085\n",
      "9 100 0.026143260300159454\n",
      "9 110 0.06757266819477081\n",
      "9 120 0.04391167312860489\n",
      "9 130 0.02304503694176674\n",
      "9 140 0.07381034642457962\n",
      "9 150 0.027121270075440407\n",
      "9 160 0.026815172284841537\n",
      "9 170 0.03963875770568848\n",
      "9 180 0.012328842654824257\n",
      "9 190 0.09601136296987534\n",
      "9 200 0.02947835996747017\n",
      "9 210 0.080451101064682\n",
      "9 220 0.06426458060741425\n",
      "9 230 0.16422441601753235\n",
      "9 240 0.02935197576880455\n",
      "9 250 0.07351094484329224\n",
      "9 260 0.04618639126420021\n",
      "9 270 0.03269251063466072\n",
      "9 280 0.04153434932231903\n",
      "9 290 0.03837776556611061\n",
      "9 300 0.10723624378442764\n",
      "9 310 0.07628179341554642\n",
      "9 320 0.019386323168873787\n",
      "9 330 0.13413891196250916\n",
      "9 340 0.014583871699869633\n",
      "9 350 0.015732400119304657\n",
      "9 360 0.0689537301659584\n",
      "9 370 0.03181954100728035\n",
      "9 380 0.021922200918197632\n",
      "9 390 0.0338229201734066\n",
      "9 400 0.07520777732133865\n",
      "9 410 0.037680644541978836\n",
      "9 420 0.17179130017757416\n",
      "9 430 0.07078052312135696\n",
      "9 440 0.0367591492831707\n",
      "9 450 0.1150771826505661\n",
      "9 460 0.07994416356086731\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    train(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "335b672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(mnist_net.state_dict(),\"/home/suzhang/git/Pytorch/HandWritingRecoData/MNIST/model/mnist_net.pt\")\n",
    "torch.save(optimizer.state_dict(),\"/home/suzhang/git/Pytorch/HandWritingRecoData/MNIST/results/mnist_optimizer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7c944090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型的加载\n",
    "mnist_net.load_state_dict(torch.load(\"/home/suzhang/git/Pytorch/HandWritingRecoData/MNIST/model/mnist_net.pt\"))\n",
    "optimizer.load_state_dict(torch.load(\"/home/suzhang/git/Pytorch/HandWritingRecoData/MNIST/results/mnist_optimizer.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "46fcd5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE=1000\n",
    "import numpy as np\n",
    "# 模型的评估\n",
    "def test():\n",
    "    loss_list=[]\n",
    "    acc_list=[]\n",
    "    mnist_net.eval()\n",
    "    test_dataloader=get_dataloader(train=False,batch_size=TEST_BATCH_SIZE)\n",
    "    for idx,(Input,target) in enumerate(test_dataloader):\n",
    "        Input=Input.to(device)\n",
    "        target=target.to(device)\n",
    "        with torch.no_grad():\n",
    "            output=mnist_net(Input)\n",
    "            output=F.log_softmax(output)\n",
    "            #output [batch_size,10] target:batch_size\n",
    "            cur_loss=F.nll_loss(output,target)\n",
    "            cur_loss=cur_loss.cpu()\n",
    "            loss_list.append(cur_loss.data.numpy())\n",
    "            #计算准确率\n",
    "            pred=output.max(dim=-1)[-1]\n",
    "            cur_acc=pred.eq(target).float().mean()\n",
    "            cur_acc=cur_acc.cpu()\n",
    "            acc_list.append(cur_acc.data.numpy())\n",
    "    print(\"平均准确率，平均损失：\",np.mean(acc_list),np.mean(loss_list))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9b3730a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suzhang/anaconda3/envs/ogb_using/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均准确率，平均损失： 0.9640001 0.13496827\n"
     ]
    }
   ],
   "source": [
    "# 未使用卷积神经网络的结果\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
